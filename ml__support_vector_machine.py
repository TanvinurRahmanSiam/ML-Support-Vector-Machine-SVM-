# -*- coding: utf-8 -*-
"""ML_ Support Vector Machine

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cobmCoSC8qjbUD-R3fFPVef7dvJeOLbv

**The Support Vector Machine, or SVM, is a linear model that can be used to solve classification and regression problems. It can solve both linear and nonlinear problems and is useful for a wide range of applications. SVM is a simple concept: The algorithm divides the data into classes by drawing a line or hyperplane.**
*When the number of features in the dataset is large compared to the number of data points, we can use SVM. By choosing the right kernel and adjusting the parameters to perfection. SVM is a good classifier, but it isn't the best. No one, in fact, could possibly be the best.*

`Pandas is primarily used to analyze data. Pandas can import data from a variety of file types, including comma-separated values (CSV), JSON, SQL database tables or queries, and Microsoft Excel.`

`The sklearn. datasets package includes some small toy datasets as well as helpers for retrieving larger datasets that are commonly used by the machine learning community to test algorithms on real-world data.`
"""

import pandas as pd
from sklearn.datasets import load_iris
iris = load_iris()

dir(iris)  #directory

iris.feature_names

df= pd.DataFrame(iris.data, columns= iris.feature_names)
df.head()

iris.target_names

df['target'] = iris.target

df[df.target == 0].head(52)   
# as here, 50 rows are present, we can use 50 or 
# more than that number to show the all rows which supports this condition.

df[df.target == 1].head()   # Finding the target.

df[df.target == 2].head(52)

"""`A lambda function is a short function that only contains one expression. Lambda functions can also be used as anonymous functions, meaning that they don't need a name. When we need to complete small tasks with minimal code, these are extremely useful.`"""

df['flower_name'] = df.target.apply(lambda x: iris.target_names[x])
df.head(151)

from matplotlib import pyplot as plt
df0 = df[df.target == 0]
df1 = df[df.target == 1]
df2 = df[df.target == 2]
df0.head()

df1.head()

df2.head()

plt.scatter(df0['sepal length (cm)'], df0['sepal width (cm)'], color='green', marker='+')

plt.scatter(df1['sepal length (cm)'], df1['sepal width (cm)'], color='red', marker='+')

plt.scatter(df2['sepal length (cm)'], df2['sepal width (cm)'], color='blue', marker='+')

plt.xlabel('petal length(cm)')
plt.ylabel('petal width(cm)')
plt.scatter(df0['petal length (cm)'], df0['petal width (cm)'], color='cyan', marker='+')
plt.scatter(df1['petal length (cm)'], df1['petal width (cm)'], color='red', marker='o')

"""`Sklearn model selection has a function called train_test_split that splits data arrays into two subsets: training data and testing data. We don't have to divide the dataset manually with this function. Sklearn train_test_split creates random partitions for the two subsets by default.`"""

from sklearn.model_selection import train_test_split
x=df.drop(['target', 'flower_name'], axis='columns')
x

y=df.target
y

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2 )

len(x_train)

len(x_test)

"""`The gamma parameter determines how far a single training example's influence extends, with low values indicating 'far' and high values indicating 'close.' The inverse of the radius of influence of samples selected by the model as support vectors are the gamma parameters.`
`The regularization parameter (lambda) is used to determine how important miss-classifications are. SVM is a quadratic optimization problem that aims to maximize the margin between the two classes while reducing miss-classifications.`
"""

from sklearn.svm import SVC
model=SVC(gamma=10)
model

model.fit(x_train, y_train)

model.score(x_test, y_test)*100